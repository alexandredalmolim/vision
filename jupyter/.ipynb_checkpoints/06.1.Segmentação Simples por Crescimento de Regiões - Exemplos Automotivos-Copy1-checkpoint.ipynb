{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](../banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"https://img.shields.io/badge/python-3.10-green\" alt=\"Python Version\" title=\"Python Version\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06.1.Segmentação Simples por Crescimento de Regiões - Exemplos Automotivos\n",
    "\n",
    "O sonho de consumo de todo aquele que desenvolve métodos de processamento de imagens é um algoritmo genérico para dividir a imagem em seus componentes. Para conseguir fazer isso, os algoritmos clássicos de segmentação baseiam-se em informação de semelhança entre os pixels e de continuidade de valores de pixels dentro da imagem (veja a minha digressão sobre *apriorismos Kantianos* na vídeoaula inicial onde eu apresento os domínios e as etapas da visão computacional), sendo provavelmente os algoritmos que de forma mais icônica incorporam o conceito de \"domínio do espaço\". \n",
    "\n",
    "Infelizmente nenhum dos algoritmos clássicos de segmentação realiza esse sonho de consumo: um algoritmo clássico que se baseia unicamente na informação contida dentro da imagem necessariamente é um algoritmo que usa apenas informação de natureza *sintática*. Toda a informação que está à disposição do algoritmo de segmentação diz respeito apenas à própria natureza da *estrutura* (sintaxe) dos pixels: seus valores, suas posições relativas uns aos outros e seus padrões de variação no espaço. Como nenhum desses algoritmos incorpora a informação *semântica*, do significado de padrões de variação e organização, todos eles necessariamente vão dividir a imagem em regiões \"parecidas\", ignorando o fato de que um carro vermelho possui pneus pretos e faróis e para-choque prateados… Durante 50 anos da história da visão computacional, o pesadelo recorrente do desenvolvedor de algoritmos de interpretação de imagens foi o de juntar estes segmentos contendo paralama, capô, pneu, calota, para-choque, etc para formar uma imagem de um \"automóvel\". Na visão clássica isso só é possível de se fazer possuindo-se um *modelo* de qual é a aparência desse \"automóvel\". Essa informação, de caráter semântico, em muito extrapola o que um algoritmo de segmentação consegue fazer. \n",
    "\n",
    "Tentativas de resolver esse problema através de um pós-processamento utilizando-se técnicas da Inteligência Artificial Simbólica Clássica Baseada em Modelos (*Model Based Reasoning*) fracassaram para todos os domínios de aplicação que fugiam do trivialmente simples. A visão computacional só conseguiu vencer essa barreira com o advento da Segmentação Semântica utilizando Redes Neurais de Aprendizado Profundo nos últimos anos. Vamos ver isso quando chegarmos nesse capítulo. Por enquanto, divirta-se com os algoritmos clássicos que foram o estado da arte durante quase 50 anos da história da visão computacional…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.1. Exemplos Automotivos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](http://lapix.ufsc.br/wp-content/uploads/2023/11/mocambiques.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sji8XdOMioaq"
   },
   "source": [
    "### Checking where you're running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUgYm9ZFioar",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "fac1383f-0857-41fd-d44d-2da6fcbdc0d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/awangenh/Documents/Aulas/VC/vision/jupyter\n",
      "Linux note 6.2.0-36-generic #37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n",
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=22.04\n",
      "DISTRIB_CODENAME=jammy\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.3 LTS\"\n",
      "Running on Google Colab =  False\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!uname -a\n",
    "!cat /etc/lsb-release\n",
    "\n",
    "# Test if your notebook is running on Google Colab\n",
    "# You'll use this when choosing between doing interaction via ipywidgets or not.\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "\n",
    "print('Running on Google Colab = ', _ON_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're running on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEhRmEwtioar"
   },
   "source": [
    "#### Cloning the ***Computer Vision*** repository from a Git\n",
    "\n",
    "If you're running this at your computer or using Google Colab but **not** using your Google Drive, this is the way to use these notebooks! Please choose only one of the two Gits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRwhf4lCioas",
    "outputId": "373feb55-62d3-403f-faf3-8fcc6e9bb36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vision'...\n",
      "remote: Enumerating objects: 3454, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 3454 (delta 5), reused 0 (delta 0), pack-reused 3435\u001b[K\n",
      "Receiving objects: 100% (3454/3454), 368.02 MiB | 24.98 MiB/s, done.\n",
      "Resolving deltas: 100% (94/94), done.\n",
      "Updating files: 100% (3528/3528), done.\n"
     ]
    }
   ],
   "source": [
    "# To clone from our personal Github mirror (may be out of sync):\n",
    "!git clone https://github.com/awangenh/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KypPTb-gioas"
   },
   "outputs": [],
   "source": [
    "# To clone from UFSC's Institutional Gitlab (always the latest version):\n",
    "!git clone https://codigos.ufsc.br/aldo.vw/vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvwJqnn6ba_9"
   },
   "source": [
    "#### Move the *data* folder\n",
    "\n",
    "Move ***vision/data*** one level up, into the root folder, so the Anconda-oriented data paths in the next cells will all work properly. If you are running this notebook from a copy of the ***vision*** Git on Anaconda, you **do not** have to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRt968M_asa3",
    "outputId": "7325204f-af98-49ce-c230-c3d232dad5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\n",
      "drwxr-xr-x 1 root root 4096 Nov  3 18:20 .\n",
      "drwxr-xr-x 1 root root 4096 Nov  3 18:21 ..\n",
      "drwxr-xr-x 4 root root 4096 Nov  2 13:23 .config\n",
      "drwxr-xr-x 1 root root 4096 Nov  2 13:24 sample_data\n",
      "drwxr-xr-x 7 root root 4096 Nov  3 18:21 vision\n",
      "mv: cannot stat 'vision/data': No such file or directory\n",
      "total 116\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:21 .\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:21 ..\n",
      "lrwxrwxrwx   1 root root     7 Jun  5 14:02 bin -> usr/bin\n",
      "drwxr-xr-x   2 root root  4096 Apr 18  2022 boot\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:20 content\n",
      "-rw-r--r--   1 root root  4332 Jun 21 00:40 cuda-keyring_1.0-1_all.deb\n",
      "drwxr-xr-x   8 root root  4096 Nov  3 18:20 data\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 datalab\n",
      "drwxr-xr-x   5 root root   360 Nov  3 18:19 dev\n",
      "-rwxr-xr-x   1 root root     0 Nov  3 18:19 .dockerenv\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:19 etc\n",
      "drwxr-xr-x   2 root root  4096 Apr 18  2022 home\n",
      "lrwxrwxrwx   1 root root     7 Jun  5 14:02 lib -> usr/lib\n",
      "lrwxrwxrwx   1 root root     9 Jun  5 14:02 lib32 -> usr/lib32\n",
      "lrwxrwxrwx   1 root root     9 Jun  5 14:02 lib64 -> usr/lib64\n",
      "lrwxrwxrwx   1 root root    10 Jun  5 14:02 libx32 -> usr/libx32\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 media\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 mnt\n",
      "-rw-r--r--   1 root root 17294 Jun 21 00:39 NGC-DL-CONTAINER-LICENSE\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:41 opt\n",
      "dr-xr-xr-x 183 root root     0 Nov  3 18:19 proc\n",
      "drwxr-xr-x  15 root root  4096 Nov  2 13:21 python-apt\n",
      "drwx------   1 root root  4096 Nov  2 13:41 root\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:15 run\n",
      "lrwxrwxrwx   1 root root     8 Jun  5 14:02 sbin -> usr/sbin\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 srv\n",
      "dr-xr-xr-x  13 root root     0 Nov  3 18:19 sys\n",
      "drwxrwxrwt   1 root root  4096 Nov  3 18:38 tmp\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 tools\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:41 usr\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 var\n"
     ]
    }
   ],
   "source": [
    "!ls -al\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "\n",
    "if  _ON_COLAB:\n",
    "    # If you are Running on Google Colab,\n",
    "    # Move vision/data one level up, into the root folder\n",
    "    !mv vision/data ..\n",
    "!ls -al .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCEqlBw6ioat"
   },
   "source": [
    "#### Mount your Google Drive as a Folder\n",
    "\n",
    "If you're using Google Colab together with your Google Drive, adapt this code below to point to the place where you've copied our Git in your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnWYJSSPioau"
   },
   "outputs": [],
   "source": [
    "# Code to mount the Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcYZ7EyUioav"
   },
   "source": [
    "Look at the contents of your Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0apzRfNRioav",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.2. Inicializações para todo o Bloco de Notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/awangenh/anaconda3/lib/python3.9/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/awangenh/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Install latest OpenCV with Python Interface using the Python Install Program\n",
    "!pip3 install opencv-python\n",
    "\n",
    "# Para gerar saída formatada\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# Leia as nossas imagens da estradinha da Praia do Moçambique, na Ilha de Santa Catarina\n",
    "mocambique1 = cv2.imread(\"../data/mocambique1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mocambique2 = cv2.imread(\"../data/mocambique2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mocambique3 = cv2.imread(\"../data/mocambique3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mocambique4 = cv2.imread(\"../data/mocambique4.png\", cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.3. K-Médias\n",
    "\n",
    "The traditional cluster analysis algorithm applied to image segmentaion: similar pixels that are in neighbouring regions are clustered into regions.\n",
    "\n",
    "### 6.1.3.1. 1º Exemplo: com uma imagem de tomografia computadorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo de k-médias**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07e1f118a6c479fb89ad52847ebbf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=52, description='n_segments', min=5), FloatSlider(value=0.55, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "# Carregue na forma de tons de cinza uma imagem de tomografia computadorizada de nossa coleção\n",
    "# CTs são imagens que servem muito bem para exemplifica a utilidade de algoritmos de crescimento de regiões\n",
    "image = cv2.imread(\"../data/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "#image = img_as_float(img[::2, ::2])\n",
    "\n",
    "\n",
    "def my_k_means(n_segments, compactness, sigma, colormap):\n",
    "    global image\n",
    "    colormap = eval('plt.cm.' + colormap)\n",
    "    segments_slic = slic(image, n_segments=n_segments, compactness=compactness, sigma=sigma)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(mark_boundaries(image, segments_slic))\n",
    "    ax[0].set_title('Original with Boundaries: SLIC (k-Means)')\n",
    "\n",
    "    ax[1].imshow(segments_slic, cmap=colormap, interpolation='nearest')\n",
    "    ax[1].set_title('Segments: SLIC (k-Means)')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "printmd(\"**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo de k-médias**\")\n",
    "interactive(my_k_means, n_segments=(5, 100), compactness=(0.1, 1.0), sigma=(0.1, 3.0), colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3.2. 2º Exemplo: Você consegue segmentar o Caminho Navegável com k-médias?\n",
    "\n",
    "Use nossas imagens do Moçambique:\n",
    "\n",
    "* Você consegue reproduzir os resultado adiante? \n",
    "* Quais parâmtros você tem de usar? \n",
    "* É possível obter algum resultado melhor alterando manualmente algum dos parâmetros, para além dos valores pré-setados nos sliders?\n",
    "* O resultado é rápido o suficiente para poder ser usado em tempo real embarcado em um carro?\n",
    "* Você conseguiu resultados similares para todas as imagens utilizando o mesmo conjunto de parâmetros ou cada imagem precisou ser processada com parâmetros individualizados? \n",
    "\n",
    "![banner cnns ppgcc ufsc](http://lapix.ufsc.br/wp-content/uploads/2023/11/mocabique-kmeans.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo de k-médias**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bcfb49c5624cca8e719abb43d17eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=52, description='n_segments', min=5), FloatSlider(value=0.55, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#image = mocambique1\n",
    "#image = mocambique2\n",
    "image = mocambique3\n",
    "#image = mocambique4\n",
    "\n",
    "printmd(\"**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo de k-médias**\")\n",
    "interactive(my_k_means, n_segments=(5, 100), compactness=(0.05, 1.0), sigma=(0.1, 3.0), colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.4. Watershed - Algoritmo do Divisor de Águas\n",
    "\n",
    "The watershed is a classical algorithm used for segmentation, that is, for separating different objects in an image.\n",
    "\n",
    "Starting from user-defined markers, the watershed algorithm treats pixels values as a local topography (elevation). The algorithm floods basins from the markers, until basins attributed to different markers meet on watershed lines. In many cases, markers are chosen as local minima of the image, from which basins are flooded. One good explanation of the Watershed Transform is provided at the page of the Centre for Mathematical Morphology, the image processing laboratory of MINES ParisTech: http://www.cmm.mines-paristech.fr/~beucher/wtshed.html. Theanimation below is from there:\n",
    "\n",
    "![](http://www.cmm.mines-paristech.fr/~beucher/lpe1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4.1. Doing Watershed with SciKit\n",
    "\n",
    "In the example below, two overlapping circles are to be separated. To do so, one computes an image that is the distance to the background. The maxima of this distance (i.e., the minima of the opposite of the distance) are chosen as markers, and the flooding of basins from such markers separates the two circles along a watershed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo do Divisor de Águas**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0096265193364187acfb9499c81185ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='gradient_method', options=('None', 'Sobel', 'Canny'), value='None'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_watershed(gradient_method, markers, colormap)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "import cv2, scipy\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import canny\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "\n",
    "#from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "image = cv2.imread(\"../data/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# shifted = cv2.pyrMeanShiftFiltering(image, 21, 51)\n",
    "\n",
    "gradient_methods = [\n",
    "    'None',\n",
    "    'Sobel',\n",
    "    'Canny'\n",
    "]\n",
    "\n",
    "def my_watershed(gradient_method, markers, colormap):\n",
    "    global image\n",
    "    colormap = eval('plt.cm.' + colormap)\n",
    "    \n",
    "    if (gradient_method == 'None'):\n",
    "        input_image = image\n",
    "    elif (gradient_method == 'Sobel'):\n",
    "        input_image = sobel(image)\n",
    "    else:\n",
    "        input_image = canny(image)\n",
    "\n",
    "    # Generate the markers as local maxima of the distance to the background\n",
    "    # Apply Exact euclidean distance transform\n",
    "    distance = ndi.distance_transform_edt(image)\n",
    "    # The peak_local_max function returns the coordinates of local peaks (maxima) in an image. \n",
    "    # A maximum filter is used for finding local maxima. This operation dilates the original \n",
    "    # image and merges neighboring local maxima closer than the size of the dilation. \n",
    "    # Coordinates where the original image is equal to the dilated image are returned as local maxima.\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((8,8)), labels=image, min_distance=20)\n",
    "    # Take the number...\n",
    "    #markers = ndi.label(local_maxi)[0]\n",
    "    #labels = watershed(-distance, markers, mask=image)\n",
    "    labels = watershed(input_image, markers=markers, connectivity=1, compactness=0.0, watershed_line=True)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(20, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow((mark_boundaries(image, labels)), cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Original with Boundaries')\n",
    "    if (gradient_method == 'None'):\n",
    "        #ax[1].imshow(distance, cmap=plt.cm.gray, interpolation='nearest')\n",
    "        ax[1].imshow(distance, cmap=plt.cm.gray)\n",
    "        ax[1].set_title('Distances')\n",
    "        # Plot the local maxima...\n",
    "        ax[1].autoscale(False)\n",
    "        ax[1].plot(local_maxi[:, 1], local_maxi[:, 0], 'r.')\n",
    "    else:\n",
    "        ax[1].imshow(input_image, cmap=plt.cm.gray)\n",
    "        ax[1].set_title(gradient_method)\n",
    "\n",
    "    ax[2].imshow(labels, cmap=colormap, interpolation='nearest')\n",
    "    ax[2].set_title('Regions')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "printmd(\"**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo do Divisor de Águas**\")\n",
    "interact_manual(my_watershed, gradient_method=gradient_methods, markers = (0, 100), colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4.2. Divisor de Águas serve para achar o Caminho Navegável?\n",
    "\n",
    "Use nossas imagens do Moçambique:\n",
    "\n",
    "* Você consegue reproduzir os resultado adiante? \n",
    "* Quais parâmtros você tem de usar? \n",
    "* É possível obter algum resultado melhor alterando manualmente algum dos parâmetros, para além dos valores pré-setados nos sliders?\n",
    "* O resultado é rápido o suficiente para poder ser usado em tempo real embarcado em um carro?\n",
    "* Você conseguiu resultados similares para todas as imagens utilizando o mesmo conjunto de parâmetros ou cada imagem precisou ser processada com parâmetros individualizados? \n",
    "\n",
    "![banner cnns ppgcc ufsc](http://lapix.ufsc.br/wp-content/uploads/2023/11/mocabique-watershed.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo do Divisor de Águas**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ef61654727473f92c2f6b889baa8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='gradient_method', options=('None', 'Sobel', 'Canny'), value='None'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_watershed(gradient_method, markers, colormap)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image = mocambique1\n",
    "#image = mocambique2\n",
    "image = mocambique3\n",
    "#image = mocambique4\n",
    "\n",
    "printmd(\"**Mova os sliders para interativamente alterar os valores dos parâmetros do algoritmo do Divisor de Águas**\")\n",
    "interact_manual(my_watershed, gradient_method=gradient_methods, markers = (0, 100), colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.5. Variantes do Watershed\n",
    "\n",
    "O video abaixo mostra uma versão refinada do algoritmo do divisor de águas, ampliada com uma representação de grafos e  desenvolvida especialmente para prcessamento de baixo custo em NVA [1] que utiliza uma semente (região vermelha) à frente do veículo para iniciar a região que deverá ser o caminho navegável. Existem outras variantes [2]. Vamos ver algoritmos de crescimento de regiões baseados em representações de grafos na parte de algoritmos clássicos avançados da disciplina. \n",
    "\n",
    "1. RATEKE, T. ; JUSTEN, K. ; CHIARELLA, V. F. ; LINHARES, R. F. ; A. C. Sobieranski ; COMUNELLO, E. ; VON WANGENHEIM, A. A fast pavement location approach for autonomous car navigation. In: CIARP 2014 - 19th Iberoamerican Congress on Pattern Recognition, 2014, Puerto Vallarta, Mexico. Proceedings of the CIARP 2014 19th Iberoamerican Congress on Pattern Recognition. Heidelberg: Springer Verlag, 2014. v. 1. https://doi.org/10.1007/978-3-319-12568-8_102\n",
    "\n",
    "1. RATEKE, THIAGO ; JUSTEN, KARLA A. ; CHIARELLA, VITO F. ; SOBIERANSKI, ANTONIO C. ; COMUNELLO, EROS ; VON WANGENHEIM, A. Passive Vision Region-Based Road Detection. ACM COMPUTING SURVEYS, v. 52, p. 1-34, 2019. http://dx.doi.org/10.1145/3311951 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"center\">\n",
       "    <iframe width=\"800\" height=\"600\"\n",
       "         src=\"https://www.youtube.com/embed/jWMAbZKi7qY\"\n",
       "    </iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div align=\"center\">\n",
    "    <iframe width=\"800\" height=\"600\"\n",
    "         src=\"https://www.youtube.com/embed/jWMAbZKi7qY\"\n",
    "    </iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](https://lapix.ufsc.br/wp-content/uploads/2022/10/rodape-CC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
