{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](../banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Python-v.3.7-green.png\" alt=\"Python Version\" title=\"Python Version\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06.2.Segmentação por Crescimento de Regiões - Algoritmos Avançados\n",
    "\n",
    "A busca pelo sonho de consumo do algoritmo genérico para dividir uma imagem nos objetos ali representados levou ao desenvolvimento de algoritmos de segmentação bastante elaborados, que tentavam unir várias técnicas diferentes e várias representações diferentes do conteúdo de uma imagem: grafos dos objetos na imagem, representação de longos gradientes suaves por grandes regiões da imagem representando o mesmo objeto que variava de luminosidade, similaridade de pixel baseada em características específicas de imagens de satélite ou outras e por aí vai. Alguns players de peso como a NASA tentaram a sua sorte neste tipo de algoritmo.\n",
    "\n",
    "A maioria desses algoritmos foram implementados em linguagens de programação compiladas e existiram apenas na forma de executáveis que podiam ser baixados ou de código fonte em linguagem C ou C++. Como a pesquisa nesses algoritmos é anterior ao grande sucesso da linguagem Python, que estamos vendo agora, e as pesquisas agora estão voltadas para o desenvolvimento de algoritmos baseados em aprendizado profundo, muito poucos dos algoritmos que discutimos na nossa aula de segmentação avançada acabaram recebendo uma implementação em Python. O algoritmo de segmentação baseado em gráficos de Felzenszwalb & Huttenlocher, que possui um nome tão prosaico que ele só é citado pelas suas iniciais FH, é um dos poucos exemplos que nós podemos executar em Python. Abaixo vão alguns exemplos de sua execução.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sji8XdOMioaq"
   },
   "source": [
    "### Checking where you're running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUgYm9ZFioar",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "fac1383f-0857-41fd-d44d-2da6fcbdc0d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/awangenh/Documents/Aulas/VC/vision/jupyter\n",
      "Linux note 6.2.0-36-generic #37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n",
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=22.04\n",
      "DISTRIB_CODENAME=jammy\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.3 LTS\"\n",
      "Running on Google Colab =  False\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!uname -a\n",
    "!cat /etc/lsb-release\n",
    "\n",
    "# Test if your notebook is running on Google Colab\n",
    "# You'll use this when choosing between doing interaction via ipywidgets or not.\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "\n",
    "print('Running on Google Colab = ', _ON_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're running on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEhRmEwtioar"
   },
   "source": [
    "#### Cloning the ***Computer Vision*** repository from a Git\n",
    "\n",
    "If you're running this at your computer or using Google Colab but **not** using your Google Drive, this is the way to use these notebooks! Please choose only one of the two Gits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRwhf4lCioas",
    "outputId": "373feb55-62d3-403f-faf3-8fcc6e9bb36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vision'...\n",
      "remote: Enumerating objects: 3454, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 3454 (delta 5), reused 0 (delta 0), pack-reused 3435\u001b[K\n",
      "Receiving objects: 100% (3454/3454), 368.02 MiB | 24.98 MiB/s, done.\n",
      "Resolving deltas: 100% (94/94), done.\n",
      "Updating files: 100% (3528/3528), done.\n"
     ]
    }
   ],
   "source": [
    "# To clone from our personal Github mirror (may be out of sync):\n",
    "!git clone https://github.com/awangenh/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KypPTb-gioas"
   },
   "outputs": [],
   "source": [
    "# To clone from UFSC's Institutional Gitlab (always the latest version):\n",
    "!git clone https://codigos.ufsc.br/aldo.vw/vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvwJqnn6ba_9"
   },
   "source": [
    "#### Move the *data* folder\n",
    "\n",
    "Move ***vision/data*** one level up, into the root folder, so the Anconda-oriented data paths in the next cells will all work properly. If you are running this notebook from a copy of the ***vision*** Git on Anaconda, you **do not** have to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRt968M_asa3",
    "outputId": "7325204f-af98-49ce-c230-c3d232dad5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\n",
      "drwxr-xr-x 1 root root 4096 Nov  3 18:20 .\n",
      "drwxr-xr-x 1 root root 4096 Nov  3 18:21 ..\n",
      "drwxr-xr-x 4 root root 4096 Nov  2 13:23 .config\n",
      "drwxr-xr-x 1 root root 4096 Nov  2 13:24 sample_data\n",
      "drwxr-xr-x 7 root root 4096 Nov  3 18:21 vision\n",
      "mv: cannot stat 'vision/data': No such file or directory\n",
      "total 116\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:21 .\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:21 ..\n",
      "lrwxrwxrwx   1 root root     7 Jun  5 14:02 bin -> usr/bin\n",
      "drwxr-xr-x   2 root root  4096 Apr 18  2022 boot\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:20 content\n",
      "-rw-r--r--   1 root root  4332 Jun 21 00:40 cuda-keyring_1.0-1_all.deb\n",
      "drwxr-xr-x   8 root root  4096 Nov  3 18:20 data\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 datalab\n",
      "drwxr-xr-x   5 root root   360 Nov  3 18:19 dev\n",
      "-rwxr-xr-x   1 root root     0 Nov  3 18:19 .dockerenv\n",
      "drwxr-xr-x   1 root root  4096 Nov  3 18:19 etc\n",
      "drwxr-xr-x   2 root root  4096 Apr 18  2022 home\n",
      "lrwxrwxrwx   1 root root     7 Jun  5 14:02 lib -> usr/lib\n",
      "lrwxrwxrwx   1 root root     9 Jun  5 14:02 lib32 -> usr/lib32\n",
      "lrwxrwxrwx   1 root root     9 Jun  5 14:02 lib64 -> usr/lib64\n",
      "lrwxrwxrwx   1 root root    10 Jun  5 14:02 libx32 -> usr/libx32\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 media\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 mnt\n",
      "-rw-r--r--   1 root root 17294 Jun 21 00:39 NGC-DL-CONTAINER-LICENSE\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:41 opt\n",
      "dr-xr-xr-x 183 root root     0 Nov  3 18:19 proc\n",
      "drwxr-xr-x  15 root root  4096 Nov  2 13:21 python-apt\n",
      "drwx------   1 root root  4096 Nov  2 13:41 root\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:15 run\n",
      "lrwxrwxrwx   1 root root     8 Jun  5 14:02 sbin -> usr/sbin\n",
      "drwxr-xr-x   2 root root  4096 Jun  5 14:02 srv\n",
      "dr-xr-xr-x  13 root root     0 Nov  3 18:19 sys\n",
      "drwxrwxrwt   1 root root  4096 Nov  3 18:38 tmp\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 tools\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:41 usr\n",
      "drwxr-xr-x   1 root root  4096 Nov  2 13:40 var\n"
     ]
    }
   ],
   "source": [
    "!ls -al\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "\n",
    "if  _ON_COLAB:\n",
    "    # If you are Running on Google Colab,\n",
    "    # Move vision/data one level up, into the root folder\n",
    "    !mv vision/data ..\n",
    "!ls -al .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCEqlBw6ioat"
   },
   "source": [
    "#### Mount your Google Drive as a Folder\n",
    "\n",
    "If you're using Google Colab together with your Google Drive, adapt this code below to point to the place where you've copied our Git in your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnWYJSSPioau"
   },
   "outputs": [],
   "source": [
    "# Code to mount the Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcYZ7EyUioav"
   },
   "source": [
    "Look at the contents of your Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0apzRfNRioav",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph-Based Methods: the Felzenszwalb & Huttenlocher Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit F&H with Grayscale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72c5ea818e43a28954eddc02ec7152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "image = cv2.imread(\"../data/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "#image = img_as_float(img[::2, ::2])\n",
    "\n",
    "\n",
    "def my_fh(scale=100, sigma=0.5, min_size=50, colormap='magma'):\n",
    "    global image\n",
    "    colormap = eval('plt.cm.' + colormap)\n",
    "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
    "    ax[0].set_title('Original with Boundaries: F&H')\n",
    "\n",
    "    ax[1].imshow(segments_fh, cmap=colormap, interpolation='nearest')\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interactive(my_fh, scale=100, sigma=0.5, min_size=50, colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit F&H with Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c229b6ea85499680e4e2c41648b614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "img = cv2.imread(\"../data/car-01.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = img_as_float(img[::2, ::2])\n",
    "\n",
    "\n",
    "def my_fh(scale=100, sigma=0.5, min_size=50):\n",
    "    global image\n",
    "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(19, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
    "    ax[0].set_title('Original with Boundaries: F&H')\n",
    "\n",
    "    ax[1].imshow(segments_fh, cmap=plt.cm.nipy_spectral, interpolation='nearest')\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interactive(my_fh, scale=100, sigma=0.5, min_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGBIS F&H Implementation\n",
    "\n",
    "Here we will use the **PEGBIS** *(Python Efficient Graph-Based Image Segmentation)*, a Python implementation by Ghassem Alaee of the \"Efficient Graph-Based Image Segmentation\" paper written by P. Felzenszwalb, D. Huttenlocher. The paper is available: http://cs.brown.edu/~pff/papers/seg-ijcv.pdf. The C++ implementation is written by the author and is available on: http://cs.brown.edu/~pff/segment/.  You'll find the original author's implementation in https://github.com/salaee/pegbis. The version we are using here had a few adaptations and Python-updates by me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this once (or each time you restart the kernel if you're using Colab)\n",
    "# Code below downloads the version stored in my mirror\n",
    "# wget parameters: \n",
    "# --backups=1 : renames original file with .1 suffix and writes new file to the intended filename\n",
    "# -q : run quiet unless there's an error\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/segment_graph.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/filter.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/fh_segment.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/disjoint_set.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f5d5121cc24cb6b13752ce739b46c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=1000, min=1), FloatSlider(value=0.5, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_pegbis(scale=100, sigma=0.5, min_size=50)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Segment an image:\n",
    "# Returns a color image representing the segmentation.\n",
    "#\n",
    "# Inputs:\n",
    "#           in_image: image to segment.\n",
    "#           sigma: to smooth the image.\n",
    "#           k: constant for threshold function.\n",
    "#           min_size: minimum component size (enforced by post-processing stage).\n",
    "#\n",
    "# Returns:\n",
    "#           num_ccs: number of connected components in the segmentation.\n",
    "# --------------------------------------------------------------------------------\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from filter import *\n",
    "from segment_graph import *\n",
    "from fh_segment import *\n",
    "import time\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "\n",
    "sigma = 0.5\n",
    "scale = 100\n",
    "min_size = 50\n",
    "input_path = \"../data/car-01.jpg\"\n",
    "\n",
    "# Loading the image\n",
    "#input_image = ndimage.imread(input_path, flatten=False, mode=None)\n",
    "input_image = plt.imread(input_path)\n",
    "\n",
    "def my_pegbis(scale=100, sigma=0.5, min_size=50):\n",
    "    global input_image\n",
    "\n",
    "    print(\"processing...\")\n",
    "    output_image, elapsed_time = fh_segment(input_image, sigma, scale, min_size)\n",
    "    print(\"Execution time: \" + str(int(elapsed_time / 60)) + \" minute(s) and \" + str(int(elapsed_time % 60)) + \" seconds\")\n",
    "    # displaying the result\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(14, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(input_image)\n",
    "    ax[0].set_title('Original')\n",
    "\n",
    "    ax[1].imshow(output_image)\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_pegbis, scale=(1, 1000), sigma=(0.1, 3.0), min_size=(10, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "* General tricks for displaying images were from here: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "* We also used a few general tips from: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rodape lapix ufsc](../rodape-CC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
